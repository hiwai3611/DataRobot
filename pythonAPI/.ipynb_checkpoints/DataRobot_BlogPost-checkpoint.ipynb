{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Tryst with Data Robot with Quality Wine\n",
    "### $\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Getting started with using DataRobot python API for multi-class classification\n",
    "###### $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Shaheen Gauher, PhD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/shaheeng/DataRobot/master/pythonAPI/image_drblog.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently, I had the opportunity to explore [DataRobot](https://www.datarobot.com/). As a hardcore pythonic data scientist, I was curious about its capabilities and wondered if it would help expedite my work. DataRobot promises [automated machine learning](https://www.datarobot.com/product/automated-machine-learning/) wherein it chooses the most appropriate machine learning algorithms, automatically optimizes data preprocessing, applies feature engineering, and tunes parameters for each algorithm. It creates and ranks highly accurate [models](https://www.datarobot.com/wiki/model/) and recommends the best model to deploy for the data and prediction target. So when the opportunity to use DataRobot presented itself, I decided to give it a try. \n",
    "\n",
    "So far, I have been quite pleased with the functionality and was able to integrate it into my pythonic workflow. I especially like how it internalises all the complexity of AutoML and presents a clean interface to work with while maintaining transparency and explainability. I have consolidated my DataRobot exploration into this tutorial on ***Getting started with using DataRobot python API for multi-class classification***. Hopefully, this will help you understand how DataRobot works and expedite the onboarding process for your data science needs within your enterprise.\n",
    "\n",
    "For this tutorial, I used the [wine quality data set](https://archive.ics.uci.edu/ml/datasets/wine+quality) from the UCI Machine Learning Repository. The dataset contains quality ratings (labels) for 4,898 white wine samples. The features are the winesâ€™ physical and chemical properties (11 predictors). We want to use these physicochemical properties to predict the quality of the wine. Data Robot expects training data in the form of a flat file. For the wine data set used here there was minimal preparation required. You can find the full code for this tutorial on [github](https://github.com/shaheeng/DataRobot/blob/master/pythonAPI/Getting_started_with_using_DataRobot_pythonAPI.ipynb) for intermediate steps. To access the DataRobot modeling engine, it is necessary to establish an authenticated [connection](https://datarobot-public-api-client.readthedocs-hosted.com/en/v2.15.0/setup/getting_started.html). With the training data prepared and connection established through my python session I will create three different projects to showcase the three different modes DataRobot can work with on my data. The three modes are the full autopilot mode, the quick autopilot mode and the manual mode. I will call the three projects corresponding to the three modes project_wine1, project_wine2, and project_wine3. Once the training process is complete, I will show how to retrieve the results from the various models and how to generate predictions on new data using a selected model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.033</td>\n",
       "      <td>48.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.99472</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.6</td>\n",
       "      <td>Med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>42.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.99080</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>11.9</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "4751            7.3              0.36         0.62             7.1      0.033   \n",
       "3047            7.7              0.18         0.53             1.2      0.041   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "4751                 48.0                 185.0  0.99472  3.14       0.62   \n",
       "3047                 42.0                 167.0  0.99080  3.11       0.44   \n",
       "\n",
       "      alcohol target  \n",
       "4751     10.6    Med  \n",
       "3047     11.9    Low  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import datarobot as dr\n",
    "\n",
    "# Prepare Training and Test Data (saved in dataframes data_train and data_test below)\n",
    "# Estabish Connection\n",
    "\n",
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame data_train contains the input to Data Robot modelling engine. We will use data_test to test the performance of the model from Data Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOPILOT_MODE.FULL_AUTO\n",
    "\n",
    "I will run the first project on full autopilot mode. Given a dataset, DataRobot starts by recommending a set of blueprints that are appropriate for the task at hand. A blueprint is a series of steps or computation paths that a dataset will pass through before producing predictions from data. There can be multiple blueprints for the same algorithm depending on the underlying preprocessing steps and each blueprint can result in one or more model. A model is the result of training a blueprint on a dataset at a specified sample percentage, a set of features and hyperparameters. \n",
    "\n",
    "In autopilot mode (which is also the default mode on DataRobot), the modeling process proceeds completely automatically including running the recommended models at different sample sizes and blending models. For the wine dataset, DataRobot recommended 22 blueprints and created 28 models based on these blueprints in less that half an hour!!!! \n",
    "\n",
    "Recommendations depend on the size and complexity of the data. For other larger datasets (~3million rows and ~50 columns) that I tried, I saw up to 60 blueprints recommendation which took a few hours to complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "[Blueprint(Vowpal Wabbit Classifier), Blueprint(Vowpal Wabbit Stagewise Polynomial Classifier), Blueprint(eXtreme Gradient Boosted Trees Classifier), Blueprint(Gradient Boosted Trees Classifier), Blueprint(RandomForest Classifier (Gini)), Blueprint(Stochastic Gradient Descent Classifier), Blueprint(Stochastic Gradient Descent Classifier), Blueprint(Stochastic Gradient Descent Classifier), Blueprint(TensorFlow Logistic Regression), Blueprint(TensorFlow Neural Network Classifier), Blueprint(Light Gradient Boosted Trees Classifier with Early Stopping (SoftMax Loss) (16 leaves)), Blueprint(ExtraTrees Classifier (Gini)), Blueprint(TensorFlow Deep Learning Classifier), Blueprint(Decision Tree Classifier (Gini)), Blueprint(Stochastic Gradient Descent Classifier), Blueprint(Majority Class Classifier), Blueprint(Regularized Logistic Regression (L2)), Blueprint(TensorFlow Deep Learning Classifier), Blueprint(Gradient Boosted Greedy Trees Classifier), Blueprint(Vowpal Wabbit Low Rank Quadratic Classifier), Blueprint(TensorFlow Deep Learning Classifier), Blueprint(Light Gradient Boosted Trees Classifier with Early Stopping (SoftMax Loss) (64 leaves))]\n"
     ]
    }
   ],
   "source": [
    "# Quickly Starting a project. Project.start method combines the project creation, file upload and target selection \n",
    "project_wine1 = dr.Project.start(data_train, project_name='shaheen_dr1',target=\"target\", target_type=dr.enums.TARGET_TYPE.MULTICLASS)\n",
    "\n",
    "# Get the recommended blueprints for this project\n",
    "allblueprints = project_wine1.get_blueprints()\n",
    "print(len(allblueprints))\n",
    "print(allblueprints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will compare all the models created using the Accuracy metric and select one model and examine its performance in detail. Then, I will upload the test_data from above to get predictions using this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models created in full auto mode =  28\n",
      "(28, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_crossValidation</th>\n",
       "      <th>accuracy_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENET Blender</td>\n",
       "      <td>0.676558</td>\n",
       "      <td>0.68740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest Classifier (Gini)</td>\n",
       "      <td>0.679748</td>\n",
       "      <td>0.68262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENET Blender</td>\n",
       "      <td>0.675916</td>\n",
       "      <td>0.68102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Advanced AVG Blender</td>\n",
       "      <td>0.670178</td>\n",
       "      <td>0.67943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model_name  accuracy_crossValidation  \\\n",
       "2                    ENET Blender                  0.676558   \n",
       "4  RandomForest Classifier (Gini)                  0.679748   \n",
       "3                    ENET Blender                  0.675916   \n",
       "7            Advanced AVG Blender                  0.670178   \n",
       "\n",
       "   accuracy_validation  \n",
       "2              0.68740  \n",
       "4              0.68262  \n",
       "3              0.68102  \n",
       "7              0.67943  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_models method returns a list of the project models that have finished training:\n",
    "allmodels = project_wine1.get_models()\n",
    "print('Number of models created in full auto mode = ',len(allmodels))\n",
    "\n",
    "# Accuracy of all models returned in full autopilot mode in order\n",
    "chosen_metric = 'Accuracy' # Options are 'Accuracy', 'Balanced Accuracy', 'LogLoss' and 'AUC'\n",
    "df_modelmetrics = pd.DataFrame(columns = ['model_name', 'accuracy_crossValidation', 'accuracy_validation']) ##create empty df\n",
    "for m in range(len(allmodels)):\n",
    "    mth_model = allmodels[m]\n",
    "    list_row = [mth_model.model_type, mth_model.metrics.get(chosen_metric).get('crossValidation'), \\\n",
    "                mth_model.metrics.get('Accuracy').get('validation') ]\n",
    "    df_modelmetrics.loc[m] = list_row\n",
    "    \n",
    "df_modelmetrics = df_modelmetrics.sort_values('accuracy_validation', ascending=False)\n",
    "print(df_modelmetrics.shape)\n",
    "df_modelmetrics.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will select the eXtreme Gradiented Boosted model and examine the metrics of the model in detail and use it to predict for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph \"Blueprint Chart\" {\n",
      "graph [rankdir=LR]\n",
      "0 [label=\"Data\"]\n",
      "-1 [label=\"Numeric Variables\"]\n",
      "1 [label=\"Missing Values Imputed\"]\n",
      "2 [label=\"eXtreme Gradient Boosted Trees Classifier\"]\n",
      "3 [label=\"Prediction\"]\n",
      "0 -> -1\n",
      "-1 -> 1\n",
      "1 -> 2\n",
      "2 -> 3\n",
      "}\n",
      "64.0123\n"
     ]
    }
   ],
   "source": [
    "# selecting a model, XGBoost for further examination\n",
    "example_model = project_wine1.get_models(search_params={'name': \"eXtreme Gradient Boosted\" })[0]\n",
    "# print blueprint chart for the selected model and look at the pre-processing steps.\n",
    "print(example_model.get_model_blueprint_chart().to_graphviz())\n",
    "print(example_model.sample_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Training Data  \n",
    "Lets extract the confusion matrix and retrieve accuracy, precision and recall for the selected model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ConfusionChart(validation), ConfusionChart(crossValidation)]\n"
     ]
    }
   ],
   "source": [
    "# Get the Confusion Chart data for the selected model.\n",
    "cms = example_model.get_all_confusion_charts()\n",
    "print(cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[369  26 282]\n",
      " [ 27 689 333]\n",
      " [160 259 990]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the crossValidation results\n",
    "crossValidation_results = cms[1]\n",
    "raw_results = crossValidation_results.raw_data\n",
    "\n",
    "# extract confusion matrix from raw results\n",
    "cm = raw_results.get('confusion_matrix')\n",
    "\n",
    "from numpy import array\n",
    "cm = array(cm)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>0.663669</td>\n",
       "      <td>0.545052</td>\n",
       "      <td>0.598540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low</td>\n",
       "      <td>0.707392</td>\n",
       "      <td>0.656816</td>\n",
       "      <td>0.681167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Med</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.702626</td>\n",
       "      <td>0.656934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class  precision    recall        f1\n",
       "0  High   0.663669  0.545052  0.598540\n",
       "1   Low   0.707392  0.656816  0.681167\n",
       "2   Med   0.616822  0.702626  0.656934"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract precion, recall and f1 for the three classes using one vs all confusion matrix from raw_results\n",
    "num_class = len(raw_results.get('class_metrics'))\n",
    "df_examplemodelmetrics = pd.DataFrame(columns = ['Class', 'precision', 'recall', 'f1']) ##create empty df\n",
    "for n in range(num_class):\n",
    "    list_row = [raw_results.get('class_metrics')[n].get('class_name') , raw_results.get('class_metrics')[n].get('precision') ,\\\n",
    "               raw_results.get('class_metrics')[n].get('recall'), raw_results.get('class_metrics')[n].get('f1')]\n",
    "    df_examplemodelmetrics.loc[n] = list_row\n",
    "\n",
    "df_examplemodelmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Test Data\n",
    "\n",
    "Now we want to test the performance of the selected model on test data. We will upload the test data, start a predict job and retrieve the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>row_id</th>\n",
       "      <th>class_High</th>\n",
       "      <th>class_Low</th>\n",
       "      <th>class_Med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Med</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222951</td>\n",
       "      <td>0.047465</td>\n",
       "      <td>0.729585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Med</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.266344</td>\n",
       "      <td>0.559053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prediction  row_id  class_High  class_Low  class_Med\n",
       "0        Med       0    0.222951   0.047465   0.729585\n",
       "1        Med       1    0.174603   0.266344   0.559053"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload test dataset\n",
    "data_test_dr = project_wine1.upload_dataset(data_test)\n",
    "# start a predict job\n",
    "predict_job = example_model.request_predictions(data_test_dr.id)\n",
    "# retrieve the predictions when complete\n",
    "predictions = predict_job.get_result_when_complete()\n",
    "predictions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the predictions retrieved as a data frame the performance metrics can be easily calculated using scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Impact\n",
    "\n",
    "DataRobot also computes [Feature Impact](https://www.datarobot.com/wiki/feature-impact/), a measure of the relevance of each feature in the model. A prerequisite to computing prediction explanations is that you need to compute the feature impact for your model (this only needs to be done once per model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'chlorides', 'citric_acid', 'density', 'fixed_acidity', 'free_sulfur_dioxide', 'pH', 'residual_sugar', 'sulphates', 'target', 'total_sulfur_dioxide', 'volatile_acidity']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>featureName</th>\n",
       "      <th>impactNormalized</th>\n",
       "      <th>impactUnnormalized</th>\n",
       "      <th>redundantWith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.306579</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volatile_acidity</td>\n",
       "      <td>0.494697</td>\n",
       "      <td>0.151664</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        featureName  impactNormalized  impactUnnormalized redundantWith\n",
       "0           alcohol          1.000000            0.306579          None\n",
       "1  volatile_acidity          0.494697            0.151664          None"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features used in the selected model\n",
    "print(example_model.get_features_used())\n",
    "# compute feature impact for selected model\n",
    "feature_impacts = example_model.get_or_request_feature_impact()\n",
    "df_feature = pd.DataFrame(feature_impacts).sort_values(by=['impactNormalized'], ascending=False)\n",
    "df_feature.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The â€˜impactUnnormalizedâ€™ is how much worse the error metric score is when making predictions on this modified data. The â€˜impactNormalizedâ€™ is normalized so that the largest value is 1. In both cases, larger values indicate more important features. If a feature is a redundant feature, i.e. once other features are considered it doesnâ€™t contribute much in additional, the â€˜redundantWithâ€™ value is the name of feature that has the highest correlation with this feature. Along with Feature Impact DataRobot can also compute the [prediction explanations](https://www.datarobot.com/wiki/prediction-explanations/) for every row of the dataset. `This functionality is however not available for multiclass models.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOPILOT_MODE.QUICK\n",
    "\n",
    "The quick mode (AUTOPILOT_MODE.QUICK) is for quickrun wherein we can run on a more limited set of models rather than the full recommended set of blueprints to get insights more quickly. In the autopilot quick mode, DataRobot built 8 models for my data in the quick mode from the 22 blueprints. We can select one of the models just like I showed above to look at the performance and to use it for getting predictions for the test data. In the quick mode DataRobot does not make any model recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blueprints =  22\n",
      "Number of models created in quick mode =  8\n"
     ]
    }
   ],
   "source": [
    "project_wine2 = dr.Project.create(data_train, project_name='shaheen_dr2')\n",
    "project_wine2.set_target('target', target_type=dr.enums.TARGET_TYPE.MULTICLASS, mode=dr.AUTOPILOT_MODE.QUICK)\n",
    "project_wine2.wait_for_autopilot()\n",
    "print('Number of blueprints = ',len(project_wine2.get_blueprints()))\n",
    "print('Number of models created in quick mode = ',len(project_wine2.get_models()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOPILOT_MODE.MANUAL\n",
    "\n",
    "In the manual mode (AUTOPILOT_MODE.MANUAL), we can select which models to execute before starting the modeling process rather than use the DataRobot autopilot. We will select the 'eXtreme Gradient Boosted Trees Classifier' blueprint and train a model using this blueprint. We can look at the performance of the manual model created in more detail as I showed above and use it for getting predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_wine3 = dr.Project.create(data, project_name='shaheen_dr3')\n",
    "project_wine3.set_target(target='target',target_type=dr.enums.TARGET_TYPE.MULTICLASS, mode=dr.AUTOPILOT_MODE.MANUAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No models get created in manual model at the start. To create a model, we will specify a blueprint to use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blueprints =  22\n",
      "Number of models created in manual mode =  0\n"
     ]
    }
   ],
   "source": [
    "print('Number of blueprints = ',len(project_wine3.get_blueprints()))\n",
    "print('Number of models created in manual mode = ',len(project_wine3.get_models()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual model created =  eXtreme Gradient Boosted Trees Classifier\n"
     ]
    }
   ],
   "source": [
    "# Select one of the blueprints instance from above to train a model. The default dataset for the project is used.\n",
    "allblueprints = project_wine3.get_blueprints()  \n",
    "# select the eXtreme Gradient Boosted Trees Classifier blueprint\n",
    "import re\n",
    "blueprint_manual = [x for x in allblueprints if re.search(\"eXtreme Gradient Boosted\", str(x))][0]\n",
    "# Train a model using 80% of the data. This train method will put a new modeling job into the queue and returns id of created ModelJob.\n",
    "manualmodel_job_id = project_wine3.train(blueprint_manual, sample_pct=80)\n",
    "\n",
    "# select the manual model created for further inverstigation\n",
    "manualmodel = project_wine3.get_models()[0]\n",
    "print('Manual model created = ',manualmodel.model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete and manage projects\n",
    "\n",
    "It is always good to cleaup after!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all my projects -  [Project(shaheen_dr3), Project(shaheen_dr2), Project(shaheen_dr1)]\n",
      "project to delete -  Project(shaheen_dr3)\n"
     ]
    }
   ],
   "source": [
    "allmyprojects = dr.Project.list()\n",
    "print('all my projects - ',allmyprojects)\n",
    "# load the project \n",
    "project_to_delete = allmyprojects[0]\n",
    "print('project to delete - ',project_to_delete)\n",
    "# delete the selected project\n",
    "project_to_delete.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope this tutorial was helpful in undertanding how DataRobot works and facilitates in integrating its rich functionality in your pythonic workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the Author:\n",
    "\n",
    "Shaheen Gauher is an AI communicator, an intelligent solution enabler and a Data Scientist by profession. She helps enterprises build and deploy predictive solutions to best leverage their data and empowers them to achieve more through technology and AI. She is a climate scientist and physicist by training and serves on the advisory board for Data Analytics at Tufts University Graduate School of Arts and Sciences. Find me on Twitter, @Shaheen_Gauher.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
